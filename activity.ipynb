{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6af0ac6",
   "metadata": {},
   "source": [
    "# COURSE: Big Data - CTS43135\n",
    "\n",
    "## Lab Instruction #6:  \n",
    "**Building a Movie Recommendation System Using PySpark and Spark MLlib**\n",
    "\n",
    "### Lab Objectives:\n",
    "- Understand how to process and analyze large-scale data using PySpark and Spark MLlib.\n",
    "- Explore and manipulate structured datasets with Spark SQL and DataFrames.\n",
    "- Implement collaborative filtering for recommendation systems using the ALS algorithm.\n",
    "\n",
    "### Prerequisites:\n",
    "- Basic knowledge of Python, SQL, and Machine Learning is recommended.\n",
    "- This lab runs on Python 3.6+ with Apache Spark 3.x.\n",
    "- A working environment like Jupyter Notebook or Google Colab is recommended for easier execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b41a4",
   "metadata": {},
   "source": [
    "### Activity 1: Preparing the MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871dd4e1",
   "metadata": {},
   "source": [
    "#### 1. Download this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27b0f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-13 08:03:17--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5917549 (5.6M) [application/zip]\n",
      "Saving to: ‘ml-1m.zip’\n",
      "\n",
      "ml-1m.zip           100%[===================>]   5.64M  3.34MB/s    in 1.7s    \n",
      "\n",
      "2025-05-13 08:03:20 (3.34 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ml-1m.zip https://files.grouplens.org/datasets/movielens/ml-1m.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b3049",
   "metadata": {},
   "source": [
    "#### 2. Extract the ZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf81d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"ml-1m.zip\", \"r\") as zip_ref:\n",
    "    # Extracts the contents into a folder named \"ml-1m\"\n",
    "    zip_ref.extractall(\"ml-1m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ab7b6",
   "metadata": {},
   "source": [
    "#### 3. Defining Schemas for MovieLens Dataset in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351272e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLensRecommendation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "    StructField(\"timestamp\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cbe42b",
   "metadata": {},
   "source": [
    "#### Task 1: create a schema for the movies.data file from the MovieLens dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f099556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "movies_schema = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5c568",
   "metadata": {},
   "source": [
    "#### 4. Load the MovieLens Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.csv(\n",
    "    'ml-1m/ml-1m/ratings.dat', sep=\"::\", schema=ratings_schema, header=False)\n",
    "ratings_df = ratings_df.drop(\"timestamp\")\n",
    "movies_df = spark.read.csv('ml-1m/ml-1m/movies.dat',\n",
    "                           sep=\"::\", schema=movies_schema, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527dc88",
   "metadata": {},
   "source": [
    "#### 5. Cache the DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6061b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/13 08:14:23 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: int, title: string, genres: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.cache()\n",
    "movies_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429aadd8",
   "metadata": {},
   "source": [
    "#### 6. Count the Number of Ratings and Movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ab9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000209 ratings and 3883 movies in the dataset.\n"
     ]
    }
   ],
   "source": [
    "ratings_count = ratings_df.count()\n",
    "movies_count = movies_df.count()\n",
    "print(\n",
    "    f\"There are {ratings_count} ratings and {movies_count} movies in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39d85c",
   "metadata": {},
   "source": [
    "#### 7. Display Sample Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb5a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Sample:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|   1193|   5.0|\n",
      "|     1|    661|   3.0|\n",
      "|     1|    914|   3.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Movies Data Sample:\n",
      "+-------+-----------------------+----------------------------+\n",
      "|movieId|title                  |genres                      |\n",
      "+-------+-----------------------+----------------------------+\n",
      "|1      |Toy Story (1995)       |Animation|Children's|Comedy |\n",
      "|2      |Jumanji (1995)         |Adventure|Children's|Fantasy|\n",
      "|3      |Grumpier Old Men (1995)|Comedy|Romance              |\n",
      "+-------+-----------------------+----------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratings Data Sample:\")\n",
    "ratings_df.show(3)  # Show first 3 rows of ratings data\n",
    "print(\"Movies Data Sample:\")\n",
    "# Show first 3 rows of movies data (without truncating movie titles)\n",
    "movies_df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84c544",
   "metadata": {},
   "source": [
    "### Activity 2: Computing Average Ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4cfa6",
   "metadata": {},
   "source": [
    "#### 1. Import Required Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc9a0e",
   "metadata": {},
   "source": [
    "#### 2. Compute the Average Ratings Per Movie. Using ratings_df, compute the average rating and the number of ratings per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids_with_avg_ratings_df = (ratings_df\n",
    "                                 .groupBy('movieId')  # Group by movie ID\n",
    "                                 .agg(F.count(ratings_df.rating).alias(\"count\"),  # Count the number of ratings\n",
    "                                      F.avg(ratings_df.rating).alias(\"average\"))  # Compute the average rating\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3191652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_ids_with_avg_ratings_df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+\n",
      "|movieId|count|average           |\n",
      "+-------+-----+------------------+\n",
      "|1580   |2538 |3.739952718676123 |\n",
      "|2366   |756  |3.6560846560846563|\n",
      "|1088   |687  |3.3114992721979624|\n",
      "+-------+-----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"movie_ids_with_avg_ratings_df:\")\n",
    "movie_ids_with_avg_ratings_df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72be76c",
   "metadata": {},
   "source": [
    "#### 3. Add Movie Titles to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9688a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names_with_avg_ratings_df = movie_ids_with_avg_ratings_df.join(\n",
    "    movies_df,  # Joining with movies dataset\n",
    "    movie_ids_with_avg_ratings_df.movieId == movies_df.movieId  # Matching on movie ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_names_with_avg_ratings_df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+-------+--------------------+------------------------------+\n",
      "|movieId|count|average           |movieId|title               |genres                        |\n",
      "+-------+-----+------------------+-------+--------------------+------------------------------+\n",
      "|1580   |2538 |3.739952718676123 |1580   |Men in Black (1997) |Action|Adventure|Comedy|Sci-Fi|\n",
      "|2366   |756  |3.6560846560846563|2366   |King Kong (1933)    |Action|Adventure|Horror       |\n",
      "|1088   |687  |3.3114992721979624|1088   |Dirty Dancing (1987)|Musical|Romance               |\n",
      "+-------+-----+------------------+-------+--------------------+------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"movie_names_with_avg_ratings_df:\")\n",
    "movie_names_with_avg_ratings_df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28af13fd",
   "metadata": {},
   "source": [
    "#### Task 2: Filter the movies dataset to include only movies with at least 500 reviews and sort them by highest average rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ab714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Movies with at least 500 reviews, sorted by highest average rating:\n",
      "+-------+-----+-----------------+-------+-------------------------------------------------------------------+-------------------------------+\n",
      "|movieId|count|average          |movieId|title                                                              |genres                         |\n",
      "+-------+-----+-----------------+-------+-------------------------------------------------------------------+-------------------------------+\n",
      "|2019   |628  |4.560509554140127|2019   |Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)|Action|Drama                   |\n",
      "|318    |2227 |4.554557700942973|318    |Shawshank Redemption, The (1994)                                   |Drama                          |\n",
      "|858    |2223 |4.524966261808367|858    |Godfather, The (1972)                                              |Action|Crime|Drama             |\n",
      "|745    |657  |4.52054794520548 |745    |Close Shave, A (1995)                                              |Animation|Comedy|Thriller      |\n",
      "|50     |1783 |4.517106001121705|50     |Usual Suspects, The (1995)                                         |Crime|Thriller                 |\n",
      "|527    |2304 |4.510416666666667|527    |Schindler's List (1993)                                            |Drama|War                      |\n",
      "|1148   |882  |4.507936507936508|1148   |Wrong Trousers, The (1993)                                         |Animation|Comedy               |\n",
      "|1198   |2514 |4.477724741447892|1198   |Raiders of the Lost Ark (1981)                                     |Action|Adventure               |\n",
      "|904    |1050 |4.476190476190476|904    |Rear Window (1954)                                                 |Mystery|Thriller               |\n",
      "|260    |2991 |4.453694416583082|260    |Star Wars: Episode IV - A New Hope (1977)                          |Action|Adventure|Fantasy|Sci-Fi|\n",
      "+-------+-----+-----------------+-------+-------------------------------------------------------------------+-------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_movies_df = (movie_names_with_avg_ratings_df\n",
    "                      .filter(movie_names_with_avg_ratings_df[\"count\"] >= 500)  # Filter movies with at least 500 reviews\n",
    "                      .orderBy(movie_names_with_avg_ratings_df[\"average\"].desc())  # Sort by highest average rating\n",
    "                      )\n",
    "\n",
    "print(\"Filtered Movies with at least 500 reviews, sorted by highest average rating:\")\n",
    "filtered_movies_df.show(10, truncate=False)  # Display the top 10 movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0227a",
   "metadata": {},
   "source": [
    "### Activity 3: Collaborative Filtering with ALS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd45e7",
   "metadata": {},
   "source": [
    "#### 1. Creating a Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3877e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/13 08:25:42 WARN BlockManager: Task 27 already completed, not releasing lock for rdd_70_0\n",
      "25/05/13 08:25:42 WARN BlockManager: Task 28 already completed, not releasing lock for rdd_71_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 600148, Validation: 200360, Test: 199701\n",
      "\n",
      "Training Sample:\n",
      "[Rating(user=1, product=1193, rating=5.0), Rating(user=1, product=661, rating=3.0), Rating(user=1, product=914, rating=3.0)]\n",
      "Validation Sample:\n",
      "[Rating(user=1, product=3408, rating=4.0), Rating(user=1, product=1035, rating=5.0), Rating(user=1, product=720, rating=3.0)]\n",
      "Test Sample:\n",
      "[Rating(user=1, product=2804, rating=5.0), Rating(user=1, product=594, rating=4.0), Rating(user=1, product=919, rating=4.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import Rating\n",
    "\n",
    "# Convert DataFrame to RDD for MLlib compatibility\n",
    "ratings_rdd = ratings_df.rdd.map(lambda row: Rating(row.userId, row.movieId, row.rating))\n",
    "# Randomly split the RDD into training (60%), validation (20%), and test (20%) sets\n",
    "seed = 1800009193\n",
    "(training_rdd, validation_rdd, test_rdd) = ratings_rdd.randomSplit([0.6, 0.2,\n",
    "0.2], seed=seed)\n",
    "# Cache the RDDs for performance\n",
    "training_rdd.cache()\n",
    "validation_rdd.cache()\n",
    "test_rdd.cache()\n",
    "# Print dataset sizes\n",
    "print(f'Training: {training_rdd.count()}, Validation: {validation_rdd.count()}, Test: {test_rdd.count()}\\n')\n",
    "# Show sample data from each dataset\n",
    "print(\"Training Sample:\")\n",
    "print(training_rdd.take(3)) # Take 3 samples from training set\n",
    "print(\"Validation Sample:\")\n",
    "print(validation_rdd.take(3)) # Take 3 samples from validation set\n",
    "print(\"Test Sample:\")\n",
    "print(test_rdd.take(3)) # Take 3 samples from test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05382f0d",
   "metadata": {},
   "source": [
    "#### 2. Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca53c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/13 08:29:18 WARN BlockManager: Task 30 already completed, not releasing lock for rdd_70_0\n",
      "25/05/13 08:29:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/05/13 08:29:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters for ALS\n",
    "rank = 10  # Number of latent factors\n",
    "iterations = 10  # Number of iterations\n",
    "reg_param = 0.1  # Regularization parameter\n",
    "\n",
    "# Train the ALS model\n",
    "model = ALS.train(training_rdd, rank, iterations=iterations, lambda_=reg_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b424df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/13 08:32:43 WARN BlockManager: Task 155 already completed, not releasing lock for rdd_72_0\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the ALS model and the test dataset\n",
    "predictions_rdd = model.predictAll(test_rdd.map(lambda x: (x.user, x.product)))\n",
    "\n",
    "# Convert predictions to the format ((userId, movieId), rating)\n",
    "predictions_rdd = predictions_rdd.map(lambda r: ((r.user, r.product), r.rating))\n",
    "\n",
    "# Convert actual ratings to the same format ((userId, movieId), rating)\n",
    "actual_ratings_rdd = validation_rdd.map(lambda x: ((x[0], x[1]), x[2]))\n",
    "# Join actual ratings with predictions\n",
    "joined_rdd = actual_ratings_rdd.join(predictions_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a271d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Compute RMSE\n",
    "mse = joined_rdd.map(lambda x: (x[1][0] - x[1][1]) ** 2).mean()\n",
    "rmse = sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f60feb",
   "metadata": {},
   "source": [
    "#### 3. Implementing Everything in a Single Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_als_model(training_rdd, validation_rdd, rank, iterations=5, reg_param=0.1):\n",
    "    \"\"\"\n",
    "    Trains an ALS model and evaluates its performance using RMSE.\n",
    "    Parameters:\n",
    "    training_rdd (RDD): Training dataset in RDD format\n",
    "    validation_rdd (RDD): Validation dataset in RDD format\n",
    "    rank (int): Number of latent factors for ALS\n",
    "    iterations (int): Number of iterations for ALS optimization\n",
    "    reg_param (float): Regularization parameter for ALS\n",
    "    Returns:\n",
    "    model: Trained ALS model\n",
    "    rmse (float): Computed RMSE value\n",
    "    \"\"\"\n",
    "    # Train ALS model\n",
    "    model = ALS.train(training_rdd, rank, iterations=iterations, lambda_=reg_param)\n",
    "    \n",
    "    # Generate predictions for validation set using predictAll\n",
    "    validation_pairs_rdd = validation_rdd.map(lambda x: (x[0], x[1]))  # Extract (userId, movieId) pairs\n",
    "    predictions_rdd = model.predictAll(validation_pairs_rdd)\n",
    "    \n",
    "    # Format predictions as ((userId, movieId), rating)\n",
    "    predictions_rdd = predictions_rdd.map(lambda r: ((r.user, r.product), r.rating))\n",
    "    actual_ratings_rdd = validation_rdd.map(lambda x: ((x[0], x[1]), x[2]))\n",
    "    \n",
    "    # Join actual ratings with predictions\n",
    "    joined_rdd = actual_ratings_rdd.join(predictions_rdd)\n",
    "    \n",
    "    # Compute RMSE\n",
    "    mse = joined_rdd.map(lambda x: (x[1][0] - x[1][1]) ** 2).mean()\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    return model, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80519a3d",
   "metadata": {},
   "source": [
    "#### 4. Train the Model with Sample Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c02c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/13 08:42:47 WARN BlockManager: Task 502 already completed, not releasing lock for rdd_70_0\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'product'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m reg_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model and get RMSE\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m als_model, rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_als_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained ALS Model with Rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[52], line 19\u001b[0m, in \u001b[0;36mtrain_als_model\u001b[0;34m(training_rdd, validation_rdd, rank, iterations, reg_param)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Generate predictions for validation set\u001b[39;00m\n\u001b[1;32m     18\u001b[0m validation_pairs_rdd \u001b[38;5;241m=\u001b[39m validation_rdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]))  \u001b[38;5;66;03m# Extract (userId, movieId) pairs\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m predictions_rdd \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_pairs_rdd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Format predictions as ((userId, movieId), rating)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m predictions_rdd \u001b[38;5;241m=\u001b[39m predictions_rdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m r: ((r\u001b[38;5;241m.\u001b[39muser, r\u001b[38;5;241m.\u001b[39mproduct), r\u001b[38;5;241m.\u001b[39mrating))\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'product'"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "rank = 8\n",
    "iterations = 5\n",
    "reg_param = 0.1\n",
    "\n",
    "# Train the model and get RMSE\n",
    "als_model, rmse = train_als_model(training_rdd, validation_rdd, rank, iterations, reg_param)\n",
    "print(f\"Trained ALS Model with Rank {rank}, RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
