{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076e55cd",
   "metadata": {},
   "source": [
    "# Lab Instruction #6: Building a Movie Recommendation System Using PySpark and Spark MLlib  \n",
    "## Lab Assignment: Spark MLlib – Book Recommendation    \n",
    "\n",
    "**Student Information**  \n",
    "- Name: Thái Hồ Phú Gia  \n",
    "- Class: 23MMT  \n",
    "- Student ID: 11012302891  \n",
    "\n",
    "**Objective**  \n",
    "- Load and process the Book-Crossing dataset using PySpark.  \n",
    "- Perform data cleaning and transformation to structure the dataset for recommendations.  \n",
    "- Use Spark MLlib’s ALS (Alternating Least Squares) to build a book recommendation system.  \n",
    "- Tune hyperparameters to optimize the recommendation model.  \n",
    "- Evaluate model performance using Root Mean Squared Error (RMSE).  \n",
    "\n",
    "**Instructions**  \n",
    "Download this dataset: Book-Crossing Dataset.  \n",
    "This dataset contains user ratings for books, which will be used to build a recommendation system using Spark MLlib. Your goal is to process the dataset using Spark and apply ALS (or similar) collaborative filtering to build a book recommendation system.  \n",
    "\n",
    "- Load and preprocess the dataset, ensuring valid user ratings.  \n",
    "- Filter out books with very few ratings to improve model performance.  \n",
    "- Train an ALS model using PySpark MLlib to generate book recommendations.  \n",
    "- Evaluate the model using Root Mean Squared Error (RMSE).  \n",
    "- Tune hyperparameters (rank, lambda_, iterations) to optimize the recommendation model.  \n",
    "- Generate and display the top 5 book recommendations for a given user.  \n",
    "\n",
    "**Submission**  \n",
    "- Submission deadline: 2 weeks from the assignment date.  \n",
    "- Submission Format: Upload the Executed Notebook (or similar) to LMS (lms.siu.edu.vn).  \n",
    "\n",
    "**Suggested Resources**  \n",
    "- [Spark Collaborative Filtering Documentation](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)  \n",
    "- [Spark SQL Documentation](https://spark.apache.org/sql/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb3c8e5",
   "metadata": {},
   "source": [
    "### 1. Load and process the Book-Crossing dataset using PySpark.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "426e7d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86373c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookRecommendation\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c55a2612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_path = \"./dataset/Ratings.csv\"\n",
    "books_path   = \"./dataset/Books.csv\"\n",
    "users_path   = \"./dataset/Users.csv\"\n",
    "\n",
    "ratings = spark.read.csv(ratings_path, header=True, inferSchema=True, sep=';')\n",
    "books   = spark.read.csv(books_path,   header=True, inferSchema=True, sep=';')\n",
    "users   = spark.read.csv(users_path,   header=True, inferSchema=True, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "276f24d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: integer (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Rating: integer (nullable = true)\n",
      "\n",
      "+-------+----------+------+\n",
      "|User-ID|ISBN      |Rating|\n",
      "+-------+----------+------+\n",
      "|276725 |034545104X|0     |\n",
      "|276726 |0155061224|5     |\n",
      "|276727 |0446520802|0     |\n",
      "|276729 |052165615X|3     |\n",
      "|276729 |0521795028|6     |\n",
      "+-------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      "\n",
      "+----------+--------------------------------------------------------------------------------------------------+--------------------+----+-----------------------+\n",
      "|ISBN      |Title                                                                                             |Author              |Year|Publisher              |\n",
      "+----------+--------------------------------------------------------------------------------------------------+--------------------+----+-----------------------+\n",
      "|0195153448|Classical Mythology                                                                               |Mark P. O. Morford  |2002|Oxford University Press|\n",
      "|0002005018|Clara Callan                                                                                      |Richard Bruce Wright|2001|HarperFlamingo Canada  |\n",
      "|0060973129|Decision in Normandy                                                                              |Carlo D'Este        |1991|HarperPerennial        |\n",
      "|0374157065|Flu: The Story of the Great Influenza Pandemic of 1918 and the Search for the Virus That Caused It|Gina Bari Kolata    |1999|Farrar Straus Giroux   |\n",
      "|0393045218|The Mummies of Urumchi                                                                            |E. J. W. Barber     |1999|W. W. Norton & Company |\n",
      "+----------+--------------------------------------------------------------------------------------------------+--------------------+----+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()\n",
    "ratings.show(5, truncate=False)\n",
    "\n",
    "books.printSchema()\n",
    "books.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb774d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User-ID: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n",
      "+-------+----+\n",
      "|User-ID|Age |\n",
      "+-------+----+\n",
      "|1      |NULL|\n",
      "|2      |18  |\n",
      "|3      |NULL|\n",
      "|4      |17  |\n",
      "|5      |NULL|\n",
      "+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()\n",
    "users.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed852f8",
   "metadata": {},
   "source": [
    "### 2. Perform data cleaning and transformation to structure the dataset for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f29ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings_clean = ratings.filter(col(\"Rating\").isNotNull() & (col(\"Rating\") > 0))\n",
    "book_counts = ratings_clean.groupBy(\"ISBN\").agg(count(\"*\").alias(\"cnt\"))\n",
    "popular_books = book_counts.filter(col(\"cnt\") >= 5).select(\"ISBN\")\n",
    "\n",
    "ratings_filt = ratings_clean.join(popular_books, on=\"ISBN\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa710284",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ratings_filt.randomSplit([0.8, 0.2], seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76dcae8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- User-ID: integer (nullable = true)\n",
      " |-- Rating: integer (nullable = true)\n",
      " |-- itemID: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------+-------+\n",
      "|ISBN      |User-ID|Rating|itemID |\n",
      "+----------+-------+------+-------+\n",
      "|0000000000|8094   |10    |11305.0|\n",
      "|0000000000|11676  |9     |11305.0|\n",
      "|0000000000|71285  |7     |11305.0|\n",
      "|0002005018|8      |5     |7054.0 |\n",
      "|0002005018|11676  |8     |7054.0 |\n",
      "+----------+-------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- User-ID: integer (nullable = true)\n",
      " |-- Rating: integer (nullable = true)\n",
      " |-- itemID: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4140:============================>                           (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------+-------+\n",
      "|ISBN      |User-ID|Rating|itemID |\n",
      "+----------+-------+------+-------+\n",
      "|0000000000|11795  |7     |11305.0|\n",
      "|0002005018|67544  |8     |7054.0 |\n",
      "|0002251760|37712  |10    |7055.0 |\n",
      "|0002558122|11676  |8     |7056.0 |\n",
      "|0006385427|38835  |10    |13356.0|\n",
      "+----------+-------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "isbn_indexer = StringIndexer(\n",
    "    inputCol=\"ISBN\",      \n",
    "    outputCol=\"itemID\"    \n",
    ").fit(train)\n",
    "\n",
    "train = isbn_indexer.transform(train)\n",
    "test  = isbn_indexer.transform(test)\n",
    "\n",
    "train.printSchema()\n",
    "train.show(5, truncate=False)\n",
    "test.printSchema()\n",
    "test.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f29d3",
   "metadata": {},
   "source": [
    "### 3. Use Spark MLlib’s ALS (Alternating Least Squares) to build a book recommendation system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e44f547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"User-ID\",     \n",
    "    itemCol=\"itemID\",\n",
    "    ratingCol=\"Rating\",\n",
    "    nonnegative=True,\n",
    "    implicitPrefs=False,\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "model = als.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f990fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMSE = 2.0300\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"Rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Initial RMSE = {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2caf7a",
   "metadata": {},
   "source": [
    "### 4. Tune hyperparameters to optimize the recommendation model and Evaluate model performance using Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb3a5f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE = 1.9652\n",
      "Best rank = 20, regParam = 0.1, maxIter = 20\n"
     ]
    }
   ],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank,        [10, 20]) \\\n",
    "    .addGrid(als.regParam,    [0.01, 0.1]) \\\n",
    "    .addGrid(als.maxIter,     [10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "cvModel = cv.fit(train)\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "bestPreds = bestModel.transform(test)\n",
    "bestRmse  = evaluator.evaluate(bestPreds)\n",
    "print(f\"Best RMSE = {bestRmse:.4f}\")\n",
    "print(f\"Best rank = {bestModel._java_obj.parent().getRank()}, regParam = {bestModel._java_obj.parent().getRegParam()}, maxIter = {bestModel._java_obj.parent().getMaxIter()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52287c8",
   "metadata": {},
   "source": [
    "### 5. Book recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23d73940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_details(isbn, books_df):\n",
    "    book = books_df.filter(col(\"ISBN\") == isbn).first()\n",
    "    if book:\n",
    "        title = book[\"Title\"] if \"Title\" in book else \"Unknown\"\n",
    "        author = book[\"Author\"] if \"Author\" in book else \"Unknown\"\n",
    "        year = book[\"Year-Of-Publication\"] if \"Year-Of-Publication\" in book else \"Unknown\"\n",
    "        return f\"{title} by {author} ({year})\"\n",
    "    return f\"Unknown book (ISBN: {isbn})\"\n",
    "\n",
    "def recommend_books_for_user(user_id, model, train_df, books_df, isbn_indexer, num_recommendations=5):\n",
    "\n",
    "    if train_df.filter(col(\"User-ID\") == user_id).count() == 0:\n",
    "        print(f\"User {user_id} not found in the training set\")\n",
    "        return\n",
    "\n",
    "\n",
    "    user_df = spark.createDataFrame([Row(**{\"User-ID\": user_id})])\n",
    "\n",
    "    recs = model.recommendForUserSubset(user_df, num_recommendations)\n",
    "    if recs.count() == 0:\n",
    "        print(f\"No recommendations could be generated for User {user_id}\")\n",
    "        return\n",
    "\n",
    "    from pyspark.sql.functions import explode\n",
    "    recs = recs.select(\"User-ID\", explode(\"recommendations\").alias(\"rec\"))\n",
    "    recs = recs.select(\"User-ID\", recs.rec.itemID.alias(\"itemID\"), recs.rec.rating.alias(\"score\"))\n",
    "\n",
    "    \n",
    "    itemid_isbn = pd.DataFrame({\n",
    "        \"itemID\": list(range(len(isbn_indexer.labels))),\n",
    "        \"ISBN\": isbn_indexer.labels\n",
    "    })\n",
    "    itemid_isbn_sdf = spark.createDataFrame(itemid_isbn)\n",
    "\n",
    "    recs = recs.join(itemid_isbn_sdf, on=\"itemID\", how=\"left\")\n",
    "\n",
    "    print(f\"\\nTop {num_recommendations} book recommendations for User {user_id}:\")\n",
    "    for i, row in enumerate(recs.collect(), 1):\n",
    "        isbn = row[\"ISBN\"]\n",
    "        print(f\"{i}. {get_book_details(isbn, books_df)} (score: {row['score']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c11c103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|User-ID|\n",
      "+-------+\n",
      "|  80945|\n",
      "|  64171|\n",
      "|  76355|\n",
      "|  44925|\n",
      "|  10917|\n",
      "|    232|\n",
      "|  15957|\n",
      "|   7346|\n",
      "|  10030|\n",
      "|  73486|\n",
      "+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select(\"User-ID\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d779c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 book recommendations for User 80945:\n",
      "1. Redeeming Love by Francine Rivers (Unknown) (score: 10.69)\n",
      "2. Per Anhalter Durch Die Galaxis by Adams (Unknown) (score: 10.65)\n",
      "3. Miles from Nowhere: A Round the World Bicycle Adventure by Barbara Savage (Unknown) (score: 10.61)\n",
      "4. Wild Orchids : A Novel by Jude Deveraux (Unknown) (score: 10.41)\n",
      "5. The Law by Frederic Bastiat (Unknown) (score: 10.34)\n"
     ]
    }
   ],
   "source": [
    "recommend_books_for_user(80945, bestModel, train, books, isbn_indexer, num_recommendations=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
